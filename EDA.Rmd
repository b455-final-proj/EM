---
title: "Exploring EM Priors"
author: "Damon Pham, Kushal Shah, Ethan Violette"
date: "April 24, 2018"
output: html_document
---

```{r setup, include=FALSE}
list.of.packages <- c('kableExtra', 'knitr', 'ggplot2','gridExtra','reshape2','grid',
                      'mgcv','e1071','randomForest','maptree','class','corrplot',
                      'tableone','NHANES','dplyr','mclust','mixtools','stats', 'mclust',
                      'plot3D','neuralnet')

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
rm(list.of.packages, new.packages)

opts_chunk$set(echo=F,
               cache=TRUE, autodep=TRUE,
               message=FALSE, warning=FALSE)
```

```{r}
evenly_spaced_quantiles = function(x, n){
  if(n == 1){ return(quantile(x, .5)) }
  else {
    probs = seq(from=0, to=1, length.out = n)
    return(quantile(x, probs))
  }
}
```

# Dataset summaries

## Banknote
```{r}
banknote <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt", header = F)
colnames(banknote) <- c("Variance", "Skewness", "Kurtosis", "Entropy", "Class")
```

```{r}
pairs(banknote[,-5], panel = panel.smooth, lower.panel = NULL, col=as.factor(banknote$Class))
```

## Iris

```{r}
pairs(iris[,-5], panel = panel.smooth, lower.panel = NULL, col=as.factor(iris$Species))
```

Petal width, petal length, and sepal length are highly linearly corrolated. 

## Diabetes

```{r}
data("diabetes")

pairs(diabetes,col=diabetes$class)
par(xpd = TRUE)
legend("bottomright", fill = unique(diabetes$class), legend = c( levels(diabetes$class)))
```

```{r}
x.1 <- rmvnorm(40, c(0, 0))
x.2 <- rmvnorm(60, c(3, 4))
X.1 <- rbind(x.1, x.2)
mu <- list(c(0))

#These lines don't run?
#out.1 <- mvnormalmixEM(x, arbvar = FALSE, mu = mu,
#                       epsilon = 1e-02)
#mvnormalmixEM(x = diabetes[,-1], mu = c(5,5,5), sigma = c(5,5,5), lambda = c(.33,.33,.34))
```

# Gaussian Mixture Models

```{r}
pairs(diabetes,col=diabetes$class)
par(xpd = TRUE)
legend("bottomright", fill = unique(diabetes$class), legend = c( levels(diabetes$class)))
```
```{r}
hist(diabetes$glucose,breaks=50)
hist(diabetes$insulin,breaks=50)
hist(diabetes$sspg,breaks=50)
```

```{r}
gmm.glucose <- normalmixEM(diabetes$glucose, lambda = c(.125,.8,.075), mu = c(50,100,150), sigma = c(20,10,50),maxit=2000,epsilon=.01)
summary(gmm.glucose)
plot(gmm.glucose, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Glucose Levels", xlab2="Glucose",breaks=25)
```

```{r}
gmm.insulin <- normalmixEM(diabetes$insulin, lambda = c(40,40,20), mu = c(350,500,1000), sigma = c(60,100,300),maxit=2000,epsilon=.01)
summary(gmm.insulin)
plot(gmm.insulin, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Insulin Levels", xlab2="Insulin",breaks=25)
```

```{r}
gmm.sspg <- normalmixEM(diabetes$sspg, lambda = c(.8,.15,.05), mu = c(130,270,500), sigma = c(70,20,200),maxit=2000,epsilon=.01)
summary(gmm.sspg)
plot(gmm.sspg, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="SSPG Levels", xlab2="SSPG",breaks=27)
```


```{r}
gmm.sspg <- normalmixEM(diabetes$sspg, lambda = c(1,1,1), mu = c(350,800,1200), sigma = c(60,200,300),maxit=2000)
summary(gmm.sspg)
```


```{r}
pairs(iris,col=iris$Species,cex=.7)
par(xpd = TRUE)
legend("bottomright", fill = unique(iris$Species), legend = c( levels(iris$Species)))
```

```{r}
banknote <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt', header=FALSE)

names(banknote) <- c("variance","skewness","kurtosis","entropy","authenticity")
banknote$authenticity <- as.factor(banknote$authenticity)
```

```{r}
pairs(banknote,panel=panel.smooth,col=banknote$authenticity,cex=.4)
par(xpd = TRUE)
legend("bottomright", fill = unique(banknote$authenticity), legend = c( levels(banknote$authenticity)))
```

```{r}
hist(banknote$variance,breaks=50) # 4 classes
hist(banknote$skewness,breaks=50) # 5 classes
hist(banknote$kurtosis,breaks=50) # 3 classes
hist(banknote$entropy,breaks=50) # 2 classes
```


```{r}
gmm.variance <- normalmixEM(banknote$variance, lambda = c(1,1,1,1), mu = c(-4,-2,0,4), sigma = c(1.5,1,1,0.5),maxit=2000,epsilon=.01)
summary(gmm.variance)
plot(gmm.variance, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Variance Levels", xlab2="Variance",breaks=25)
```

```{r}
gmm.skewness <- normalmixEM(banknote$skewness, lambda = c(.05,.2,.25,.2,.3), mu = c(-13,-7,0,3,8), sigma = c(1,2,1.5,1.5,3),maxit=2000,epsilon=.01)
summary(gmm.skewness)
plot(gmm.skewness, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Skewness Levels", xlab2="Skewness",breaks=25)
```

```{r}
gmm.kurtosis <- normalmixEM(banknote$kurtosis, lambda = c(.2,.6,.2), mu = c(-4,0,6), sigma = c(2,2,3),maxit=2000,epsilon=.01)
summary(gmm.kurtosis)
plot(gmm.kurtosis, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Kurtosis Levels", xlab2="Kurtosis",breaks=25)
```

```{r}
gmm.entropy <- normalmixEM(banknote$entropy, lambda = c(.3,.7), mu = c(-4,0), sigma = c(2,1),maxit=2000,epsilon=.01)
summary(gmm.entropy)
plot(gmm.entropy, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Entropy Levels", xlab2="Entropy",breaks=25)
```


```{r}
gmm.glucose <- normalmixEM(diabetes$glucose, lambda = c(1,1,1), mu = evenly_spaced_quantiles(diabetes$glucose, 3), sigma = c(70,70,70)* runif(1,.9,1.1), maxit=2000, epsilon = .01)

gmm.insulin <- normalmixEM(diabetes$insulin, lambda = c(1,1,1), mu = evenly_spaced_quantiles(diabetes$glucose, 3), sigma = c(319,319,319)* runif(1,.9,1.1),maxit=2000, epsilon = .01)
summary(gmm.insulin)

gmm.sspg <- normalmixEM(diabetes$sspg, lambda = c(1,1,1), mu = evenly_spaced_quantiles(diabetes$glucose, 3), sigma = c(121,121,121)* runif(1,.9,1.1),maxit=2000, epsilon = .01)
summary(gmm.sspg)

plot(gmm.glucose, density=TRUE, cex.axis=1.4, cex.lab=1.4, cex.main=1.8,main2="Glucose Levels", xlab2="Glucose",breaks=20)
```

```{r}
gmm.glucose <- normalmixEM(diabetes$glucose, lambda = c(1,1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1),rnorm(1,1,1)), sigma = c(70,70,70)* runif(1,.9,1.1),maxit=2000, epsilon = .01)

gmm.insulin <- normalmixEM(diabetes$insulin, lambda = c(1,1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1),rnorm(1,1,1)), sigma = c(319,319,319)* runif(1,.9,1.1),maxit=2000, epsilon = .01)
summary(gmm.insulin)

gmm.sspg <- normalmixEM(diabetes$sspg, lambda = c(1,1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1),rnorm(1,1,1)), sigma = c(121,121,121)* runif(1,.9,1.1),maxit=2000, epsilon = .01)
summary(gmm.sspg)
```

```{r}
gmm.variance <- normalmixEM(banknote$Variance, lambda = c(1,1,1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1),rnorm(1,2,1),rnorm(1,3,1)), sigma = c(3,3,3,3)* runif(1,.9,1.1),maxit=2000, epsilon = .01)

gmm.skewness <- normalmixEM(banknote$Skewness, lambda = c(1,1,1,1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1),rnorm(1,2,1),rnorm(1,3,1),rnorm(1,4,1)), sigma = c(6,6,6,6,6)* runif(1,.9,1.1),maxit=2000, epsilon = .01)

gmm.entropy <- normalmixEM(banknote$Entropy, lambda = c(1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1)), sigma = c(2.1,2.1)* runif(1,.9,1.1),maxit=2000, epsilon = .01)
summary(gmm.entropy)

gmm.kurtosis <- normalmixEM(banknote$Kurtosis, lambda = c(1,1,1), mu = c(rnorm(1,0,1),rnorm(1,1,1),rnorm(1,2,1)), sigma = c(4.3,4.3,4.3)* runif(1,.9,1.1),maxit=2000, epsilon = .01)
summary(gmm.kurtosis)
```

```{r}
gmm.variance <- normalmixEM(banknote$Variance, lambda = c(1,1,1,1), mu = evenly_spaced_quantiles(banknote$Variance, 4), sigma = c(3,3,3,3),maxit=2000, epsilon = .01)
summary(gmm.variance)
qskew <- quantile(banknote$Skewness)

gmm.skewness <- normalmixEM(banknote$Skewness, lambda = c(1,1,1,1,1), mu = evenly_spaced_quantiles(banknote$Skewness, 5), sigma = c(6,6,6,6,6),maxit=2000, epsilon = .01)

gmm.entropy <- normalmixEM(banknote$Entropy, lambda = c(1,1), mu = evenly_spaced_quantiles(banknote$Entropy, 2), sigma = c(2.1,2.1),maxit=2000, epsilon = .01)
summary(gmm.entropy)

gmm.kurtosis <- normalmixEM(banknote$Kurtosis, lambda = c(1,1,1), mu = evenly_spaced_quantiles(banknote$Kurtosis, 3), sigma = c(4.3,4.3,4.3),maxit=2000, epsilon = .01)
summary(gmm.kurtosis)
```


# EM Algorithm

```{r setup, include=FALSE}
list.of.packages <- c('kableExtra', 'knitr', 'ggplot2','gridExtra','reshape2','grid')
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
rm(list.of.packages, new.packages)

opts_chunk$set(echo=FALSE, cache=TRUE, autodep=TRUE,
               message=FALSE, warning=FALSE,
               fig.align="center")

source('scripts.R')
```

Our own implementation converges correctly when the initial prior distributions are within range of the true prior distributions. Below are plots showing the data distribution (x) and a sample from the solved MOG (y). Clearly, the distributions are near-identical.

```{r}
set.seed(0)
x = generate.mog(n.data=1000, mu=c(0,.8, .3), sigma=c(.01,.01,.02), prior=c(.6,.2,.2))
hist(x, breaks=100)

ans1 = EM(data=x, n.classes=3, prior.choice='equal.priors.random.params', max.iters=1000)

y = generate.mog(n.data=1000, mu=as.numeric(ans1$mu), sigma=ans1$sigma, prior=ans1$prior)
hist(y, breaks=100)
```

However, when the true prior distributions are on a different magnitude, the algorithm fails to converge.

```{r}
set.seed(0)
x = generate.mog(n.data=1000, mu=c(0,8, 3), sigma=c(.1,.1,.2), prior=c(.6,.2,.2))
hist(x, breaks=100)

ans2 = EM(data=x, n.classes=3, prior.choice='equal.priors.random.params', max.iters=1000)

y = generate.mog(n.data=1000, mu=as.numeric(ans2$mu), sigma=ans2$sigma, prior=ans2$prior)
hist(y, breaks=100)
```

We were able to implement a function which generates multivariate MOGs. We were also able to make an EM algorithm which returns a result, but not an accurate one. We think it has the same issue as in the univariate setting of finding a bad local maximum. We did not bother to debug it since this issue was already past our abilities to resolve in the univariate setting.

```{r}
set.seed(0)
x = generate.mog(n.data=1000, mu=matrix(c(-1,0,2,-1,1,1), nrow=3),
                 sigma=replicate(3, matrix(c(.3,.1,.1,.3), nrow=2)), 
                 prior=c(.4,.4,.2))
plot(x[,1], x[,2])

ans3 = EM(data=x, n.classes=3, prior.choice='equal.priors.random.params', max.iters=1000)

y = generate.mog(n.data=1000, mu=ans3$mu, sigma=ans3$sigma, prior=ans3$prior)
plot(y[,1], y[,2])
```
